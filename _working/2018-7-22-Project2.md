# Project 2 - Predicting NBA Winning Percentage in Upcoming Season
#### by Anders Olson-Swanson

## Setup
Our second project at Metis was called Project Luther and it was about web scraping and linear regression.

I'm a huge basketball fan so my mind immediately tried to figure out how I could incorporate the sport with the project. After several hours of brainstorming, I decided to try create a model that would predict the winning percentage of a given NBA team at the start of the season before any games have been played. My goal was to try to take this model to see if one could potentially use it to make money by gambling.

## Data Acquisition and Initial Steps
I wanted to use the previous seasons' team statistics and any other team information that would be available at the start of a given season. I decided to pull my statistics and information from the website https://www.basketball-reference.com/. This website has an enormous amount of statistics for each season going back decades. I ended up pulling about 40 years worth of various stats, including overall team stats, coach information, and player information. I used BeautifulSoup in order to scrape this information from the website.

Once I had the data in a single pandas dataframe, I immediately separated out a portion of my data to be used for final testing. I chose to holdout the 2018 season, since I wanted to combine my predictions for that year with gambling data. I then ran a baseline linear model to get a starting point. The feature I chose was average margin of victory from the previous season because I felt that would be a decent predictor of the success of the following season.

## Fine Tuning My Model
My next step was to try running all my features together. This increased my R<sup>2</sup> value slightly, but my model now had over thirty features. I started to remove features that didn't seem to improve my model. It turned out that there were quite a few features that I could remove without decreasing my R<sup>2</sup> value very much.

After narrowing down my feature list, I tried adding polynomial terms to see if that could improve my model. Mostly it didn't, but there were two specific polynomial features that slightly increased the R<sup>2</sup>. Throughout my feature engineering, I used Lasso cross validation to test my model, and to continue removing unneeded features.

## Final Model
In the end, my final model included Lasso regularization and included features such as average age of the players, margin of victory, number of points scored, number of returning players, and number of blocks. had the following statistics.

Metric | Value
------ | -----
Features | 17
R<sup>2</sup> | 0.408
RMSE | 0.11

The R<sup>2</sup> wasn't as high as I had hoped but given the problem, it was probably what could be expected. The root mean squared error looks great at first glance, until you remember that I was predicting a percentage. That RMSE is equivalent to about 9 games of an 82 game season which is pretty variable. The model's most important features were margin of victory and average age of the players, which is not surprising.

## Gambling
My next question was can this model be used to win money by gambling. I scraped over/under betting from a betting [website](http://www.vegasinsider.com/nba/story.cfm/story/1865923). If you're not familiar with sports betting, I will briefly explain over/under betting. Vegas gives each team an expected number of wins in the upcoming season and you then bet that the team will either win more games (over) or win less games (under). If you end up being correct, you win.

I initially tested my predictions for all the teams against the gambling information and was correct on only 50%, just as good as flipping a coin. Interestingly, if I focused just on the eight teams where my model prediction was very close to the vegas over/under number, I was correct 87.5%. This seems great but I would want to test this on other years before believing that number was something other than happenstance.

## Where is the Model Wrong?
Since my model wasn't great a predicting, I decided to see if there was a specific reason why. The residual plot below shows that my model is overpredicting when the actual winning percentage is low and underpredicting when the actual winning percentage is high.

![](https://github.com/aos226/aos226.github.io/blob/master/images/Luther_residual.png)

I picked a few examples of where my model prediction was very off and found that there were consistent reasons why. The following table shows the team, year, the difference between my prediction and the actual winning percentage, and the reason why my prediction was so wrong.

Team | Year | Difference | Reason
---- | ---- | ---------- | ------
San Antonio Spurs | 1996-97 | -0.41 | David Robinson broke his foot
Cleveland Cavaliers | 2010-11 | -0.38 | LeBron James left team
Chicago Bulls | 1998-99 | -0.35 | Michael Jordan retired
Miami Heat | 2007-08 | -0.35 | Dwayne Wade injured throughout season
Houston Rockets | 1982-83 | -0.34 | Moses Malone left team
Phoenix Suns | 2004-05 | 0.36 | Steve Nash joined team
Boston Celtics | 2007-08 | 0.32 | Kevin Garnett and Ray Allen joined team
Cleveland Cavaliers | 2008-09 | 0.32 | No single reason
San Antonio Spurs | 1989-90 | 0.30 | David Robinson joined team

In general, when my model significantly overpredicted, the team lost it's best player for some reason. When my model significantly underpredicted, the team added it's best player in the offseason. While my model accounted for the number of returning players, it didn't distinguish between a superstar and a bench warmer. I believe if I incorporated that information, my model would be a much better predictor.
